{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3IB5cSthGnw"
   },
   "source": [
    "# 텍스트 전처리 파이프라인\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/corazzon/Mastering-NLP-from-Foundations-to-LLMs/refs/heads/main/cover.png'\n",
    "     alt=\"NLP와 LLM 실전 가이드(한빛미디어)\"\n",
    "     style=\"border: 3px solid gray; box-shadow: 5px 5px 15px rgba(0, 0, 0, 0.3); border-radius: 10px; width: 300px;\"   width='300'>\n",
    "\n",
    "\n",
    "* 저자:  \n",
    "    - [Lior Gazit](https://www.linkedin.com/in/liorgazit).  \n",
    "    - [Meysam Ghaffari](https://www.linkedin.com/in/meysam-ghaffari-ph-d-a2553088/).\n",
    "* 역자:\n",
    "    - [박조은](https://github.com/corazzon)\n",
    "* 이 노트북은 다음의 책에서 소개하는 내용입니다.\n",
    "    - 역서 : NLP와 LLM 실전 가이드(한빛미디어)\n",
    "    - 원서 : [Mastering NLP from Foundations to LLMs](https://www.amazon.com/dp/1804619183)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO3hrUVTRoMN"
   },
   "source": [
    "**이 노트북의 목적:**  \n",
    "책의 4장에서 설명했듯이, 텍스트 전처리는 자연어 처리(NLP)에서 가장 기본적인 작업 중 하나입니다.  \n",
    "이 노트북에서는 다양한 전처리 기능을 단계별로 설명하며, 이를 통합하여 견고한 파이프라인을 구성하는 방법을 보여줍니다.  \n",
    "\n",
    "**필수 사항:**  \n",
    "* Colab에서 실행 시, 다음 런타임 노트북 설정을 사용하세요: `Python3, CPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph5DfybXiP_-"
   },
   "source": [
    "colab 실습 : \n",
    "https://github.com/corazzon/Mastering-NLP-from-Foundations-to-LLMs\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/corazzon/Mastering-NLP-from-Foundations-to-LLMs/blob/main/Chapter4_notebooks/Ch4_Preprocessing_Pipeline.ipynb)  \n",
    "\n",
    "\n",
    "원서 Colab 실습:  \n",
    "https://github.com/PacktPublishing/Mastering-NLP-from-Foundations-to-LLMs   \n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PacktPublishing/Mastering-NLP-from-Foundations-to-LLMs/blob/liors_branch/Chapter4_notebooks/Ch4_Preprocessing_Pipeline.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g54Uf66Vz9Fi"
   },
   "source": [
    ">*```면책사항: 이 노트북에서 다루는 내용과 아이디어는 저자들 개인의 것이며, 저자들의 고용주의 견해나 지적 재산을 대변하지 않습니다.```*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayuVflRZ5w9C"
   },
   "source": [
    "설치:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3609,
     "status": "ok",
     "timestamp": 1732675809769,
     "user": {
      "displayName": "오늘코드todaycode",
      "userId": "06313463015165663090"
     },
     "user_tz": -540
    },
    "id": "DhrOK1E1lxTo"
   },
   "outputs": [],
   "source": [
    "# 주의사항:\n",
    "# 아래 코드에서 Python 패키지 불일치로 인한 오류가 발생하는 경우, 새로운 버전이 원인일 수 있습니다.\n",
    "# 이런 경우, \"default_installations\"를 False로 설정하여 원래 이미지로 되돌리세요:\n",
    "default_installations = True\n",
    "if default_installations:\n",
    "    !pip install -q num2words autocorrect\n",
    "else:\n",
    "    import requests\n",
    "    text_file_path = \"requirements__Ch4_Preprocessing_Pipeline.txt\"\n",
    "    url = \"https://raw.githubusercontent.com/PacktPublishing/Mastering-NLP-from-Foundations-to-LLMs/main/Chapter4_notebooks/\" + text_file_path\n",
    "    res = requests.get(url)\n",
    "    with open(text_file_path, \"w\") as f:\n",
    "        f.write(res.text)\n",
    "\n",
    "    !pip install -r requirements__Ch4_Preprocessing_Pipeline.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11283,
     "status": "ok",
     "timestamp": 1732675824097,
     "user": {
      "displayName": "오늘코드todaycode",
      "userId": "06313463015165663090"
     },
     "user_tz": -540
    },
    "id": "3M3KTFuMSgCf",
    "outputId": "e150aeca-26ac-4be8-e075-1e802573985e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Imports:\n",
    "import re\n",
    "from num2words import num2words\n",
    "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1732675828784,
     "user": {
      "displayName": "오늘코드todaycode",
      "userId": "06313463015165663090"
     },
     "user_tz": -540
    },
    "id": "ivh-TwcqSnVd"
   },
   "outputs": [],
   "source": [
    "# 전처리 함수:\n",
    "def decode(text):\n",
    "    \"\"\"\n",
    "    입력 문자열에서 주제 줄(subject line)과 본문 텍스트(body text)를\n",
    "    정규식을 사용해 추출합니다. 추출된 텍스트를 단일 문자열로\n",
    "    포맷하여 반환합니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    text = re.sub(\"\\\\n|\\\\r|\\\\t|-\", \" \", text)\n",
    "    subject_line_search = re.search(r\"<SUBJECT LINE>(.*?)<END>\", text, flags=re.S)\n",
    "    body_text_search = re.search(r\"<BODY TEXT>(.*?)<END>\", text, flags=re.S)\n",
    "\n",
    "    formated_output = \"\"\n",
    "    if subject_line_search:\n",
    "        formated_output = formated_output + subject_line_search.groups()[0] + \". \"\n",
    "    if body_text_search:\n",
    "        formated_output = formated_output + body_text_search.groups()[0] + \".\"\n",
    "    return formated_output\n",
    "\n",
    "\n",
    "def digits_to_words(match):\n",
    "    \"\"\"\n",
    "    문자열로 된 숫자를 영어 단어로 변환합니다. 이 함수는 기수(cardinal)와\n",
    "    서수(ordinal)를 구분합니다.\n",
    "    예: \"2\"는 \"two\"로, \"2nd\"는 \"second\"로 변환됩니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    suffixes = ['st', 'nd', 'rd', 'th']\n",
    "    # 이전 작업에 의존하지 않도록 소문자로 변환:\n",
    "    string = match[0].lower()\n",
    "    if string[-2:] in suffixes:\n",
    "        type = 'ordinal'\n",
    "        string = string[:-2]\n",
    "    else:\n",
    "        type = 'cardinal'\n",
    "\n",
    "    return num2words(string, to=type)\n",
    "\n",
    "\n",
    "def spelling_correction(text):\n",
    "    \"\"\"\n",
    "    잘못된 철자를 올바른 철자로 교정합니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    corrector = Speller()\n",
    "    spells = [corrector(word) for word in text.split()]\n",
    "    return \" \".join(spells)\n",
    "\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    불용어(stopwords)를 제거합니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in text.split() if word not in stopwords_set])\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    \"\"\"\n",
    "    각 단어에 대해 어간 추출(stemming)을 수행합니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def lemmatizing(text):\n",
    "    \"\"\"\n",
    "    각 단어에 대해 표제어 추출(lemmatization)을 수행합니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1732675830064,
     "user": {
      "displayName": "오늘코드todaycode",
      "userId": "06313463015165663090"
     },
     "user_tz": -540
    },
    "id": "U7wnjrxqS0Ub"
   },
   "outputs": [],
   "source": [
    "# 전처리 파이프라인:\n",
    "def preprocessing(input_text, printing=False):\n",
    "    \"\"\"\n",
    "    이 함수는 텍스트 전처리를 위한 전체 파이프라인을 나타냅니다.\n",
    "\n",
    "    코드 설계 참고: \"output\" 변수를 업데이트하면서 진행하는 방식은\n",
    "    새로운 변수 이름을 생성하지 않으므로 작업 순서를 변경하거나\n",
    "    작업을 추가/제거하는 것이 용이합니다.\n",
    "\n",
    "    입력: str\n",
    "    출력: str\n",
    "    \"\"\"\n",
    "    output = input_text\n",
    "\n",
    "    # 디코딩/인코딩 제거:\n",
    "    output = decode(output)\n",
    "    print(\"\\n디코딩/인코딩 제거:\\n        \", output)\n",
    "\n",
    "    # 소문자로 변환:\n",
    "    output = output.lower()\n",
    "    print(\"\\n소문자로 변환:\\n        \", output)\n",
    "\n",
    "    # 숫자를 단어로 변환:\n",
    "    # 다음 정규 표현식은 연속된 숫자와 서수 접미사를 잠정적으로 포함한 패턴을 찾습니다:\n",
    "    output = re.sub(r'\\d+(st)?(nd)?(rd)?(th)?', digits_to_words, output, flags=re.IGNORECASE)\n",
    "    print(\"\\n숫자를 단어로 변환:\\n        \", output)\n",
    "\n",
    "    # 구두점 및 기타 특수 문자 제거:\n",
    "    output = re.sub('[^ A-Za-z0-9]+', '', output)\n",
    "    print(\"\\n구두점 및 기타 특수 문자 제거:\\n        \", output)\n",
    "\n",
    "    # 철자 교정:\n",
    "    output = spelling_correction(output)\n",
    "    print(\"\\n철자 교정:\\n        \", output)\n",
    "\n",
    "    # 불용어 제거:\n",
    "    output = remove_stop_words(output)\n",
    "    print(\"\\n불용어 제거:\\n        \", output)\n",
    "\n",
    "    # 어간 추출:\n",
    "    output = stemming(output)\n",
    "    print(\"\\n어간 추출:\\n        \", output)\n",
    "\n",
    "    # 표제어 추출:\n",
    "    output = lemmatizing(output)\n",
    "    print(\"\\n표제어 추출:\\n        \", output)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5567,
     "status": "ok",
     "timestamp": 1732675836613,
     "user": {
      "displayName": "오늘코드todaycode",
      "userId": "06313463015165663090"
     },
     "user_tz": -540
    },
    "id": "2Duu0SyeS2jW",
    "outputId": "4308251e-4e88-4011-8c13-f2d660911bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the input raw text:\n",
      "\n",
      "\"<SUBJECT LINE> Employees details<END><BODY TEXT>Attached are 2 files,\n",
      "1st one is pairoll, 2nd is healtcare!<END>\"\n",
      "\n",
      "\n",
      "디코딩/인코딩 제거:\n",
      "          Employees details. Attached are 2 files, 1st one is pairoll, 2nd is healtcare!.\n",
      "\n",
      "소문자로 변환:\n",
      "          employees details. attached are 2 files, 1st one is pairoll, 2nd is healtcare!.\n",
      "\n",
      "숫자를 단어로 변환:\n",
      "          employees details. attached are two files, first one is pairoll, second is healtcare!.\n",
      "\n",
      "구두점 및 기타 특수 문자 제거:\n",
      "          employees details attached are two files first one is pairoll second is healtcare\n",
      "\n",
      "철자 교정:\n",
      "         employees details attached are two files first one is payroll second is healthcare\n",
      "\n",
      "불용어 제거:\n",
      "         employees details attached two files first one payroll second healthcare\n",
      "\n",
      "어간 추출:\n",
      "         employe detail attach two file first one payrol second healthcar\n",
      "\n",
      "표제어 추출:\n",
      "         employe detail attach two file first one payrol second healthcar\n",
      "\n",
      "----------------------------\n",
      "This is the preprocessed text:\n",
      "        employe detail attach two file first one payrol second healthcar\n"
     ]
    }
   ],
   "source": [
    "# Applying preprocessing:\n",
    "raw_text_input = \"\"\"\n",
    "\"<SUBJECT LINE> Employees details<END><BODY TEXT>Attached are 2 files,\\n1st one is pairoll, 2nd is healtcare!<END>\"\n",
    "\"\"\"\n",
    "print(f\"This is the input raw text:\\n{raw_text_input}\")\n",
    "\n",
    "print(f\"\\n----------------------------\\nThis is the preprocessed text:\\n        {preprocessing(raw_text_input, printing=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1732675623847,
     "user": {
      "displayName": "오늘코드todaycode",
      "userId": "06313463015165663090"
     },
     "user_tz": -540
    },
    "id": "pMKB4Uk8kv46"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
